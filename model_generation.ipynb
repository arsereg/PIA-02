{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d5464fcb-607a-4905-9f20-29398d88964f",
   "metadata": {},
   "source": [
    "print(\"Keras version: \", keras.__version__)\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print('GPUs available: ', tf.config.experimental.list_physical_devices('GPU'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b2027fbf265b80ac",
   "metadata": {},
   "source": [
    "data_1 = pd.read_csv('mit-bih-data-clear-data.csv')\n",
    "data_2 = pd.read_csv('ptb-diagnostic-clear-data.csv')\n",
    "data_3 = pd.read_csv('autonomic-aging-a-dataset-clear-data.csv')\n",
    "\n",
    "\n",
    "# Feature cleanup\n",
    "df = pd.concat([data_1, data_2, data_3], ignore_index=True)\n",
    "\n",
    "df.value_counts('diagnosis')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Take 50 samples of each class and remove them from the original dataframe\n",
    "\n",
    "class_zero = df[df['diagnosis'] == 0].sample(50)\n",
    "class_one = df[df['diagnosis'] == 1].sample(50)\n",
    "\n",
    "df = df.drop(class_zero.index)\n",
    "df = df.drop(class_one.index)"
   ],
   "id": "98eb18461dd1ce8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.value_counts('diagnosis')",
   "id": "fc8dc872ce524162",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_zero.to_csv('virgin_class_zero.csv', index=False)\n",
    "class_one.to_csv('virgin_class_one.csv', index=False)"
   ],
   "id": "cea1515c8c1a99f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36942b258a8247b4",
   "metadata": {},
   "source": [
    "# Let's check for missing values\n",
    "\n",
    "df.isnull().sum()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de44a323895139d4",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X = df.drop(columns=['diagnosis'])\n",
    "y = df['diagnosis']\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "df_upsampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_upsampled.value_counts('diagnosis')\n",
   "id": "2f4bac48b23b1f2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Uncomment to check Pairplot\n",
    "# import seaborn as sns\n",
    "# sns.set_theme(style='ticks')\n",
    "# \n",
    "# sns.pairplot(df_upsampled, hue='diagnosis', kind='kde', corner=True)"
   ],
   "id": "80ca41dccb3be7db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "important_features = [\n",
    "    'minimum_hrv',\n",
    "    'maximum_hrv',\n",
    "    'standard_deviation_hrv',\n",
    "    'mean_hr_slope',\n",
    "    'tendency_slope',\n",
    "    'lowest_heart_rate',\n",
    "    'vlf_power',\n",
    "    'lf_power',\n",
    "    'hf_power',\n",
    "    'approximation_entropy'\n",
    "]\n",
    "from sklearn.impute import SimpleImputer\n",
    "target = 'diagnosis'\n",
    "\n",
    "features = df_upsampled[important_features]\n",
    "features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features = imputer.fit_transform(features)\n",
    "features = scaler.fit_transform(features)\n",
    "df = pd.DataFrame(features, columns=important_features)\n",
    "df[target] = df_upsampled[target]\n",
    "\n",
    "df.to_csv('heart_rate_final_data.csv', index=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(df.corr())\n",
    "plt.show()"
   ],
   "id": "3bf0b45be1f1b77",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc7484cb7eef4694",
   "metadata": {},
   "source": [
    "X = df.drop(columns=['diagnosis'])\n",
    "y = df['diagnosis']\n",
    "\n",
    "X.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e9d4b810",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)"
   ],
   "id": "94de96d8c52fd2ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import Sequential, Input\n",
    "from keras.api.layers import Dense, Dropout\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "\n",
    "accuracy_scores = []\n",
    "i = 0\n",
    "\n",
    "def create_model():\n",
    "    l1_regulizer = l1(0.0001)\n",
    "    l2_regulizer = l2(0.0001)\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(2048, activation='relu', kernel_regularizer=l1_regulizer),\n",
    "        Dropout(0.5),\n",
    "        Dense(1024, activation='relu', kernel_regularizer=l2_regulizer),\n",
    "        Dropout(0.4),\n",
    "        Dense(512, activation='relu', kernel_regularizer=l1_regulizer),\n",
    "        Dropout(0.4),\n",
    "        Dense(256, activation='relu', kernel_regularizer=l2_regulizer),\n",
    "        Dropout(0.4),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l1_regulizer),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2_regulizer),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu', kernel_regularizer=l1_regulizer),\n",
    "        Dropout(0.1),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=keras.api.optimizers.Adam(learning_rate=0.000001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "initial_weights = model.get_weights()\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(f'Training fold {fold}...')\n",
    "\n",
    "    if fold > 0:\n",
    "        model.set_weights(previous_weights)\n",
    "\n",
    "\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "\n",
    "    from keras.api.callbacks import ModelCheckpoint, EarlyStopping\n",
    "    checkpoint = ModelCheckpoint(f'model_{i}.keras', save_best_only=True)\n",
    "    early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_fold, y_train_fold, epochs=200, batch_size=8, verbose=0, callbacks=[checkpoint, early_stopping], validation_data=(X_test_fold, y_test_fold))\n",
    "    previous_weights = model.get_weights()\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = (model.predict(X_test_fold) > 0.6).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    cm = confusion_matrix(y_test_fold, y_pred)\n",
    "    cr = classification_report(y_test_fold, y_pred)\n",
    "    print(f\"Fold {i}\")\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", cr)\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'Model {i} Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'Model {i} Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "    i += 1"
   ],
   "id": "5862c212",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f121fb7",
   "metadata": {},
   "source": [
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
