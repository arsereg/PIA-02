{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e50faffa678adebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T08:24:37.129025Z",
     "start_time": "2024-11-28T08:24:36.972555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gino/miniconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minimum_hrv</th>\n",
       "      <th>maximum_hrv</th>\n",
       "      <th>standard_deviation_hrv</th>\n",
       "      <th>mean_hr_slope</th>\n",
       "      <th>tendency_slope</th>\n",
       "      <th>lowest_heart_rate</th>\n",
       "      <th>vlf_power</th>\n",
       "      <th>lf_power</th>\n",
       "      <th>hf_power</th>\n",
       "      <th>approximation_entropy</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.374146</td>\n",
       "      <td>0.045390</td>\n",
       "      <td>-0.139430</td>\n",
       "      <td>0.044145</td>\n",
       "      <td>-0.034767</td>\n",
       "      <td>-0.384133</td>\n",
       "      <td>0.361527</td>\n",
       "      <td>0.751998</td>\n",
       "      <td>1.006693</td>\n",
       "      <td>1.131604</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.575255</td>\n",
       "      <td>0.842270</td>\n",
       "      <td>0.329886</td>\n",
       "      <td>-0.268611</td>\n",
       "      <td>-0.032885</td>\n",
       "      <td>-0.919950</td>\n",
       "      <td>0.329070</td>\n",
       "      <td>0.480614</td>\n",
       "      <td>0.313016</td>\n",
       "      <td>0.874099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.103900</td>\n",
       "      <td>-0.990027</td>\n",
       "      <td>-0.748447</td>\n",
       "      <td>-0.094926</td>\n",
       "      <td>-0.157838</td>\n",
       "      <td>0.924604</td>\n",
       "      <td>-0.383874</td>\n",
       "      <td>-0.512656</td>\n",
       "      <td>-0.455975</td>\n",
       "      <td>0.906763</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.662117</td>\n",
       "      <td>1.124841</td>\n",
       "      <td>1.137952</td>\n",
       "      <td>-0.451958</td>\n",
       "      <td>-0.221305</td>\n",
       "      <td>-0.812195</td>\n",
       "      <td>3.251255</td>\n",
       "      <td>3.914102</td>\n",
       "      <td>4.118389</td>\n",
       "      <td>-0.390129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008774</td>\n",
       "      <td>0.751536</td>\n",
       "      <td>-0.621267</td>\n",
       "      <td>-0.083110</td>\n",
       "      <td>-0.070251</td>\n",
       "      <td>-0.319761</td>\n",
       "      <td>-0.174066</td>\n",
       "      <td>-0.128543</td>\n",
       "      <td>-0.360613</td>\n",
       "      <td>0.422274</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   minimum_hrv  maximum_hrv  standard_deviation_hrv  mean_hr_slope  \\\n",
       "0    -0.374146     0.045390               -0.139430       0.044145   \n",
       "1    -0.575255     0.842270                0.329886      -0.268611   \n",
       "2    -0.103900    -0.990027               -0.748447      -0.094926   \n",
       "3    -0.662117     1.124841                1.137952      -0.451958   \n",
       "4     0.008774     0.751536               -0.621267      -0.083110   \n",
       "\n",
       "   tendency_slope  lowest_heart_rate  vlf_power  lf_power  hf_power  \\\n",
       "0       -0.034767          -0.384133   0.361527  0.751998  1.006693   \n",
       "1       -0.032885          -0.919950   0.329070  0.480614  0.313016   \n",
       "2       -0.157838           0.924604  -0.383874 -0.512656 -0.455975   \n",
       "3       -0.221305          -0.812195   3.251255  3.914102  4.118389   \n",
       "4       -0.070251          -0.319761  -0.174066 -0.128543 -0.360613   \n",
       "\n",
       "   approximation_entropy  diagnosis  \n",
       "0               1.131604        0.0  \n",
       "1               0.874099        0.0  \n",
       "2               0.906763        0.0  \n",
       "3              -0.390129        0.0  \n",
       "4               0.422274        0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import hr_engine\n",
    "healthy = pd.read_csv('virgin_class_zero.csv')\n",
    "unhealthy = pd.read_csv('virgin_class_one.csv')\n",
    "df = pd.concat([healthy, unhealthy], ignore_index=False)\n",
    "important_features = [\n",
    "    'minimum_hrv',\n",
    "    'maximum_hrv',\n",
    "    'standard_deviation_hrv',\n",
    "    'mean_hr_slope',\n",
    "    'tendency_slope',\n",
    "    'lowest_heart_rate',\n",
    "    'vlf_power',\n",
    "    'lf_power',\n",
    "    'hf_power',\n",
    "    'approximation_entropy'\n",
    "]\n",
    "df[important_features] = hr_engine.scale_for_prediction(df[important_features])\n",
    "\n",
    "# df = df[important_features + ['diagnosis']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b50992e86a9260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T08:24:37.142720Z",
     "start_time": "2024-11-28T08:24:37.139892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "0.0    50\n",
       "1.0    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1812b45c2439651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T08:24:37.189167Z",
     "start_time": "2024-11-28T08:24:37.186865Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "target_column = 'diagnosis'\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30530f9af1515bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T08:24:42.528280Z",
     "start_time": "2024-11-28T08:24:37.229096Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 03:25:44.442946: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-28 03:25:44.449381: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732785944.457858  135510 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732785944.460391  135510 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-28 03:25:44.469041: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1732785945.542902  135510 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21659 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732785946.262896  135629 service.cc:148] XLA service 0x7b6e3c005930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732785946.262915  135629 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-11-28 03:25:46.265816: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1732785946.283207  135629 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-28 03:25:46.638758: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_26', 196 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2024-11-28 03:25:46.743259: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_26_0', 76 bytes spill stores, 248 bytes spill loads\n",
      "\n",
      "2024-11-28 03:25:47.024613: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_33_0', 88 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "2024-11-28 03:25:47.080618: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_33', 220 bytes spill stores, 220 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 1s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732785947.503252  135629 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-28 03:25:48.201461: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_33', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-28 03:25:48.222014: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_33', 220 bytes spill stores, 220 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 357ms/step\n",
      "Confusion Matrix:\n",
      " [[47  3]\n",
      " [ 3 47]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94        50\n",
      "         1.0       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.94      0.94      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n",
      "Accuracy: 0.94\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step\n",
      "Confusion Matrix:\n",
      " [[47  3]\n",
      " [ 3 47]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94        50\n",
      "         1.0       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.94      0.94      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n",
      "Accuracy: 0.94\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b704840b380> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 307ms/stepWARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b704840b380> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step\n",
      "Confusion Matrix:\n",
      " [[47  3]\n",
      " [ 3 47]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94        50\n",
      "         1.0       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.94      0.94      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n",
      "Accuracy: 0.94\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step\n",
      "Confusion Matrix:\n",
      " [[47  3]\n",
      " [ 3 47]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94        50\n",
      "         1.0       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.94      0.94      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n",
      "Accuracy: 0.94\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step\n",
      "Confusion Matrix:\n",
      " [[47  3]\n",
      " [ 3 47]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94        50\n",
      "         1.0       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.94      0.94      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n",
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "from keras.src.saving.saving_lib import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "number_of_models = 5\n",
    "\n",
    "for i in range(len(range(number_of_models))):\n",
    "    \n",
    "    model_name = f'model_{i}'\n",
    "    # Load model\n",
    "    model = load_model(f'./{model_name}.keras')\n",
    "    from sklearn.metrics import confusion_matrix,classification_report\n",
    "    \n",
    "    y_pred = (model.predict(X) > 0.6).astype(\"int32\")\n",
    "    score = accuracy_score(y, y_pred)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    cr = classification_report(y, y_pred)\n",
    "    \n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", cr)\n",
    "    print(f\"Accuracy: {score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
